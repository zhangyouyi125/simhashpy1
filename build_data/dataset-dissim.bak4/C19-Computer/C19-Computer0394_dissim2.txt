信息与控制
Information and Control
1999年　第28卷　第4期　Vol.28　No.4　1999



带神经网络补偿的极点配置广义
最小方差自校正控制
靳其兵　李鸿儒　顾树生

　　摘　要： 首先用一个常规线性模型对被控对象进行辨识，再对线性模型辨识的余差用一个神 经网络进行补偿。线性模型和神经网络共同构成对象的辨识模型，并基于这一模型提出了一 种显式极点配置广义最小方差自校正控制。该方法适用于非线性对象，且具有较高精度和较 快的收敛速度，具有较强的鲁棒性。 
　　关键词： 神经网络，极点配置，广义最小方差自校正控制
　　中图分类号：TP13　　　　　　文献标识码：B

GENERALIZED POLE PLACEMENT SELF-TUNING CONTROL WITH
NEURAL NETWORK COMPENSATION
JIN Qibing1　LI Hongru2　GU Shusheng2
(1. Beijing Institute of Petrochemical Technology, Beijing　10260 0;
2. School of Information Science & Engineering,Northeastern University 11000 6)
Abstract: The Controlled plant is identified using normal lin ear model, and then the deviation identified by linear model is compensated via a neural network. The identification model is composed of a linear model and a neural network. Based on this model, an explicit generalized pole placement self -tuning control algorithm with neural network compensation is proposed. This al gorithm is suitable for nonlinear system, and has higher precision, faster conve rgent speed and stronger robustness.
Key words　neural network, pole placement, general minimum va riance self-tuning control

1　引言
　　为了能够控制非线性对象和提高自适应控制的精度和鲁棒性，近年来，提出了带神经网络补 偿的自适应控制［1～3］。[2]中提出了带神经网络补偿的预测控制，在用神经网络进行预测补偿时，要用到未来时刻的控制量输入，而未来时刻的控制量输入是未知的，通常采用的处理方法是将前一时刻的控制序列作为已知量加入。用降级或者 变换方法以减少变量数或者找到对数据的恒定的表示;(5)选取适当的数据采掘任务: 决定KD D处理的目标是否是分类、回归、聚类等;(6)选择数据采掘的算法：选择用于寻找数据中模 式的方法;(7)进行数据采掘，发掘数据所包含的模式;(8)解释所发现的模式并形式化;(9) 整理已发现的知识：检验所发掘的知识然后予以应用。从1995年开始举行每年一届的KDD 国际会议，AAAI和IJCAI 这两大AI系列会议均开设了KDD专题，各种有关KDD的专辑和杂志 层出不穷。
2　对象的辨识模型
　　设对象特性可表示为：
y(k)=f[y(k-1),y(k-2),…,y(k-n),u(k-d),u(k-d-1),　　　　　　　　
…,u(k-d-m),ξ(k),ξ(k-1),…,ξ(k-nc)]　　　　　　　　　　　(1)
其中，n,m,nc为阶次，d为时间延迟，ξ(k)表示随机干扰。首先用如下常规线性模型对被控对象进行辨识
y(k)=-a1y(k-1)-a2y(k-2)-…-any(k-n)+b0u(k-d)+b1u(k-d-1)　　　　　
+…bmu(k-d-m)+ξ(k)+clξ(k-1)+…+cncξ(k-nc)　　　　　　(2)
辨识以后得到i(i=1,…,n),j(j=1,…,m),l(l=1,…,nc), 利用i、j、l就可以对k时刻的对象输出进行估计，估计值记为yL(k),则
　(3)
　　由于非线性、时变及未建模动态的影响，yL(k)和对象的实际输出y(k)将存在余差y(k)-yL(k)，这个余差可以用一个神经网络进行逼近，记神经网络的输出为yN(k), 则
yN(k)=g1[y(k-1),y(k-2),…,y(k-n),u(k-d),…,u(k-d-m)]　　　　　(4)
利用(1),将y(k-i)(i=1,2,…,d+1)依次代入(4)，并不考虑干扰的影响，得到
yN(k)=g[y(k-d),y(k-d-1),…,y(k-d-n+1),u(k-d-1),…,u(k-2d-m+1)]　　　(5)
对神经网络进行训练的目的是为了满足以下性能指标函数：
J1=min|y(k)-yL(k)-yN(k)|
从而可以得到：
y(k)=yL(k)+yN(k)+e(k)　　　　　　　　　　　　　　(6)
其中e(k)为最后的辨识误差，将(3)和(5)代入(6)，得到

即　　　　　A(z-1)y(k)=z-dB(z-1)u(k)+C(z-1)ξ(k)+yN(k)+e(k)　　　　　　　　　　(7)
　　　　　　　
　　　　　　　
　　　　　　　
　　(7)即为本文所采用的辨识模型，仿真表明，这种结构对非线性、带随机干扰的对象具有很高的精度。在[2][3]也采用了相似的结构。
　　神经网络可以采用前向神经网络，也可以采用动态递归神经网络，采用前向神经网络将具有 较多的输入个数，为了避免局部极小和提高权值的收敛速度，可以采用[4]中的权值训练方法。采用动态递归神经网络可以避免(5)中输入阶次的影响，大大减少网络的输入个数，采用[5]中提出的最优学习率进行仿真,我们得到了较好的效果。
3　带神经网络补偿的极点配置广义最小方差自校正控制
　　由于带神经网络补偿的模型结构的特殊性，就要求采用显式自适应控制，[6]提出了一种极点配置广义最小方差自校正显式控制算法，该算法能够保证全局的收敛性。为了全局的收敛性，本文就应用这一算法，并提出了带神经网络补偿的极点配置广义最小方差自校正控制。
　　设性能指标函数为
J2=E([P(z-1)y(k+d)-R(z-1w(k)+Q(z-1)u(k)]2}　　　　　　　　(8)
式中，w(k)为参考输入，P(z-1)、Q(z-1)、R(z-1)为z-1的加权多项式。于是一个新的研究领域―数据库中的知识发现（Knowledge Discovery in Databases简称KDD) 也就应运而生，而且在近几年里迅速发展起来。
　　　　　　　　　　　　Gy(k)+BEu(k)+Nξ(k)+EyN(k+d)=Rw(k)-Qu(k)
即　　　　　　　　　　　(BE+Q)u(k)=Rw(k)-Gy(k)-Nξ(k)-EyN(k+d)　　　　　　　　　(12)
　　将(12)式的控制量方程代入(7)式，得到对象的输出方程为
　　　　(13)
　　上式中yN(k)也可以看成可测干扰。 由(13)可见，虽然引入了具有非线性特性的神经网络进行补偿, 但系统的特征多项式仍为PB+AQ，和基于线性对象设计时是一致的。并且， 令yN(k)=0、e(k)=0,就可以得到线性设计时的对象输出方程。
　　给定稳定的期望闭环极点多项式T(z-1),得到以下极点配置方程
P(z-1)B(z-1)+A(z-1)Q(z-1)=T(z-1)　　　　　　　　　　(14)
控制量u(k)由(12)决定, 但是k时刻(12)式中的yN(k+d-i)(i=0,1,…,d-1)未知。为 了求取u(k),本文采用以下处理方法。
　　由(5)式可知
yN(k+d-i)=g[y(k-i),y(k-i-1),…,y(k-n+1-i),u(k-i),u(k-i-1),
…,u(k-d-m+1-i)]
则yN(k+d-1)、yN(k+d-2)、…yN(k+1)可以由k时刻以前的输入、输出加入经过训练 的神经网络直接求得。
　　利用一阶Tayler展开，并定义
　　
　　得到
yN(k+d)=g[y(k),…,y(k-n+1),u(k),u(k-1),…,u(k-d-m+1)]　　　　　　　
≈g0+g1*[u(k)-u(k-1)]　　　　　　　　　　　　　　　(15)
在K时刻，用u(k-1)取代加入经过训练的神经网络，神经网络的输出即为g0，g1的求取 对前向神经网络可参见[7], 对动态递归神经网络可参见[8]。
　　将(15)代入(12), 得到
　　　　　　　　(16)
　　(16)即为本文控制量u(k)的实际求取方程。
　　自适应控制的步骤如下：
　　①给定期望的极点多项式T(z-1)。
　　②测取对象的输出y(k)，对(2)式的线性模型进行辨识。
3.2.3 混合法[55]
　　在文献[55]中采用遗传算法删剪已经训练好的神经元网络拓扑结构，然后把删剪好的 网络转化为M树，而M是输出单元的数目并等于问题的类数，最后，通过分析每棵树提取出适 合每类的规则集。
　　④利用(14)式求P(z-1)、Q(z-1)。一个关联规则简记为 XY的形式，这里X∈Γ，且X∩Y=φ。
　　⑥用u(k-1)代替u(k)加入经过训练的神经网络得到g0；求取g1。现简要介绍如下。
3.2 应用神经元网络（基于BP算法）实现Data Mining。
　　⑨k=k+1, 转向步骤②。但总的来说,当前的各种KDD方法, 都是从数据库本身的信息出发,挖掘 出有意义的模式,用户的经验、常识等无法利用,其原因之一是缺乏有效的表示和处理的手段 。在\间隔内产生2000个随机数加入仿真对象，利用产生的输入、输出数据对模型进行预训练。随机干扰的最大幅值为 0.2。期望的极点多项式取为

如果利用预训练后的模型参数直接设计控制器，而不进行参数的在线校正，则由于工作点的 变化、非线性及未建模动态的影响，结果是发散的。之后逐渐升温，越来越多的研究者投身其中。采用带神经网络补偿的极点配置广义自校正控制的结果示 于图2。
　　　　　　
　　图1　极点配置广义自校正控制的结果　　　　图2　带神经网络补偿的极点配置广义自校正
　　　　　　　　　　　　　　　　　　　　　　　　　控制的结果
　　由仿真结果可以看出，本文所提出的方法是有效的，具有较快的响应速度。
5　结论
　　理论分析和仿真结果都表明了本文所提出的带神经网络补偿的极点配置广义最小方差自校正 控制方法是有效的，它比极点配置自校正控制具有更高的控制精度、更快的响应速度、更好 的鲁棒性，且适用于非线性对象。
　　在过去的几年里，用ANN技术提取规则(包括“crisp”和模糊两类)的若干方法已经提出来了，从已训练好的多层神经网络提取“crisp”(乾脆的)规则的技术，例如BRINNE技术[48]和KT算法[49]以及由Yoon Byungjao等人提出通过“destructive learning”(毁坏性学习)提取规则[50]和Ishikawa,M.提出结构的学习及其应用于规则的提取[51]
　　作者等人提出一种由预处理和规则提取两阶段组成的方法[53]，预处理阶段中包含有动态修正、聚类和删枝三部分