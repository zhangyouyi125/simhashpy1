计算机应用
Computer Applications
1999年 第19卷 第7期  Vol.19 No.7 1999



基于注释的视频索引*
郑　鹏　李订方　刘海青

　　摘　要　本文提出了表示视频数据库的数据模型，该模型通过视频注释来描述视频数据，并利用注释建立索引，以实现按内容访问视频数据库。例如，语音播放结束，摘机/挂机完成等引起的事件。在我国,计算机声讯服务系统的研究分为两类［2］：一类是以硬件为主的计算机电话语音卡的开发和研制;另一类是以软件为主的高级开发平台及应用程序的研究。
　　考虑到视频数据的特点，我们提出了基于特征的视频索引。这种方法的主要缺点是特征缺乏语义信息，例如一些用统计矩表示的特征，使得用户在对视频数据库查询时感到不便。为此，我们提出了基于注释的视频索引。多任务操作一旦在软件中发出一道指令，该任务立即提交给语音卡，由其在后台完成该任务，同时，程序控制权已转回应用软件的下一语句。对大多数应用来说整个视频流作为一个抽象层次太粗糙；另一方面，一个单独的帧很少是感兴趣的单元。于是我们把原始视频流按镜头(shot)分段［1］，以镜头作为视频流的基本单位，把这些基本单位存储在媒体上，形成一个存储的媒体段库。镜头是摄像机在一次拍摄过程中所记录下的视频帧序列，加上特征和注释组成镜头库。有了镜头库后，我们就可根据应用的需要建立视频文档库，形成用户视图。视频文档可以是场景、序列、复合单元等。这些视频区间在不同的精细程度上反映了视频信息。我们把视频数据库系统看成是由存储的媒体段、镜头和视频文档三个层次组成。对镜头库和视频文档库都可采用如下的数据模型：
　　V ：视频区间：(oid,tb,te)
　　　：特 征：(F1,F2,…Fn)
　　　：注 释：(A1,A2,…Am) 　(1)
　　其中，oid表示区间标识符，tb,te分别表示起始帧与终止帧。
　　对镜头库而言，特征是指每个镜头所独有的，与其它镜头没有关系,我们称之为上下文无关；注释也是针对单个镜头进行的。如果接入互联网，经过适当的改进，可以实现电话访问电子邮件的功能。对视频区间的注释依赖于上下文。而这一点正好反映了视频数据的时间维度。
　　实际执行的程序流主要由表中的数据而不是程序的逻辑决定的，这反映了事件驱动的原理。我们采用面向对象的方法，把每一类信息都定义成对象，相同类型的对象构成一个集合，几个集合的集合就构成视频数据库。为了便于浏览和查询，需要引入现实世界的关系实体对媒体流进行解释。视频文档可以包含结构信息，结构可用结构元素集来表示，每一个元素可识别一个视频流区间。层次模型支持对视频结构的描述，这样允许用户在不同的层次上对视频进行检索，以满足不同用户的要求。
　　为了对基本段进行注释，引入几个语义实体：
　　人物： 包括姓名、年龄、国籍和职业等属性。应用程序使用状态机来管理每一个通道的程序流。
　　事件： 包括事件类型、事件发生的时间和对事件的描述等属性。
　　物理对象： 包括对象类型和对象描述的属性。例如：有效/无效的访问，关键码达到最大录音时间等。因为对视频数据的注释与其上下文密切相关，对上下文的控制显得尤为重要。
　　作者单位：刘宝旨（山东济宁医学院计算机中心　山东．济宁 272113）
参考文献
［1］　王晶如,等.计算机电话综合系统的构成与应用.现代电信科技, 1997；(7)
［2］　张延平.电话语音系统的集成和设计.世界电信，1997；(2)
［3］　Voice software reference for MS-DOS.Dialogic Corporation, 1995 
　　收稿日期:1999-01-07(修改稿)
。为此，我们把上下文分成三个层次：
　　基本上下文： 对存储的媒体段中的单个段进行的描述。存储的媒体段是真正存储在物理设备上的视频实体。



图1　基于注释的索引

　　初级上下文： 把存储的媒体段进行编辑合成后，形成视频文档，视频文档是呈现给用户的视图，是逻辑上的。对视频文档的访问最后要映射到存储的媒体段上，物理存储与逻辑视图的分离有利于视频数据的共享和重用。对一个具体的视频文档进行的描述称为初级上下文。
　　次级上下文： 一个视频文档(D1)中的某些段被另一视频文档(D2)所共享，即出现在另一视频文档(D2)中，则在视频文档(D2)中对此共享段的描述称为视频文档(D1)的次级上下文。
　　提出三级上下文的原因是这样做可以更好地控制视频数据的共享和对视频数据的描述。在基本上下文中的注释，可被使用此存储媒体段的所有视频文档“看”到和共享，在某一视频文档的初级上下文中的注释不会与其它视频文档的初级上下文中的注释混淆，即使两者使用了某些相同的存储媒体段，在必要时，可使用次级上下文来搜索与当前上下文中的注释使用了相同存储媒体段的其它视频文档。
2　视频注释
　　我们可以利用这几个语义实体对基本段进行注释。注释就是与特定视频段相关的语义属性集。不同的视频段，其注释是不同的。
　　在存储的媒体流中，ms是存储的媒体段，(ms.SID)是其标识符，(ms.TS)是其绝对的起始时间，(ms.TE)是其绝对的终止时间，(ms.TimeUnitSize)是其时间坐标系统的时间单位。存储的媒体段的集合称为MS―Set。
　　视频文档中的每一段和每一个镜头都称为视频流区间(StreamInt)，所有的视频流区间构成视频流区间集(StreamInt―Set)。StreamInt定义如下：
　　StreamInt＝(oid,MS―ref,TS,TE) 其中
　　　TS≤TE∧存在ms∈MS―Set
　　　(MS―ref=ms∧ms.TS≤TS∧ms.TE≥TE)　　　(2)
　　MS―ref是ms的标识符，oid是视频流区间的标识符，TS、TE分别表示起始帧和终止帧。从(1)式可以看出视频流区间可以是相关视频存储段的一部分或全部。在此基础上定义视频注释如下：
　　Annot=(oid,a1,a2,...,am,SI―ref) 其中
　　SI―ref∈StreamInt―Set∧a1,a2,...,am
　　　　是具体的属性类型　　　　　　　(3)
　　在视频数据库中，除了语义注释可以帮助理解视频信息以外，视频结构也有助于理解视频信息。前面提出的层次模型支持对视频结构的解释。一般可把视频文档定义成镜头、场景、序列和复合单元。结构元素的一个重要方面就是能够表示不同精细程度的上下文，如表示镜头的上下文比表示序列的上下文要精细一些。
　　结构元素是结构元素集合(Struct―Set)的一个成员，定义如下：
　　StructComp=(oid,Type,a1,a2,...,am,SI―ref) 其中
　　　SI―ref∈StreamInt―Set
　　　∧эvs∈VS―Set(SI―ref.MS―ref=vs)
　　　∧Type∈{cu,seq,sence,shot}∧a1,a2,...,am是类型说明的属性　　　(4)
　　视频结构是与视频文档相关的，与存储的媒体段不相关，在我们的模型中指出了视频流有镜头、场景、序列、复合单元等。
　　图1说明了基于注释的索引。其中Ⅰ、Ⅱ是两个视频文档，Ⅲ、Ⅳ、Ⅴ是存储的视频段，（Ⅲ，50，950），（Ⅳ，100，700），（Ⅴ，200，600）分别是Ⅲ、Ⅳ、Ⅴ的基本上下文，（Ⅰ，100，1600），（Ⅱ，200，1201）分别是Ⅰ、Ⅱ的初级上下文，由于Ⅰ、Ⅱ中对Ⅳ共享，它们互为次级上下文，次级上下文是一个虚拟的概念，所有的描述都是在基本上下文和初级上下文中完成。
　　注释a1-a6是在存储的媒体段上的基本上下文进行的，Rowe等［2］使用术语感觉索引(sensory indexes)表示这类信息，这类索引是独立于初级上下文的，反映了视频的语法信息。注释a7、a8是在视频文档的初级上下文中进行的，Rowe等使用术语主题索引来表示这类信息，这类索引依赖于用户对视频材料的使用方式和目的，反映了视频的语义信息。
　　通道状态机的建立步骤：
　　为每一个通道列出所有可能的状态；
　　列出所有可能的改变通道状态的事件；
　　创建一个状态转换表，该表为每一个状态定义了基于当前发生的事件的下一个状态；
　　利用状态转换表，设计处理事件的程序流程。为了有效地管理和利用视频数据，人们自然想到建立视频数据库。由于视频数据的信息含量非常丰富，结构复杂多样，因此要想有效地检索视频数据，必须对视频数据建立索引。世界上对视频数据库的研究只是最近几年的事，目前还没有成熟的商用系统。可由函数putevt()将用户自定义事件加入到事件队列中来完成。这一方法的优点是很好地反映了视频数据的语义特性，缺点是注释往往要手工进行，这就使得注释的成本较高并且与注释者有关，这一问题的解决依赖于人工智能的新进展。由于视频数据库是一个较新的领域，其索引方法有待进一步研究。
　　
　　郑　鹏　博士研究生。 研究方向：机器视觉与图像处理。
　　* 本文受国家电力公司计算机应用重点学科专项基金的资助。
　　作者单位：郑　鹏　李订方　刘海青（武汉水利电力大学计算机科学与技术系　湖北．武汉430072）
参考文献
［1］　Arun Hampapur. Design Video Data Management System. Ph.D thesis, 1995
［2］　L.A.Rowe, J.S.Boreczky，C.A.Eads. Indexes for User Access to Large Video Databases. In Proceedings of the IS&T/SPIE Symposium on Electronic Imaging Science and Technology, Conference on Storage and Retrieval for Image and Video DatabasesⅡ, San Jose,CA,February 1994
［3］　Rune Hjelsvold. Sharing and Reuse of Video Information. In Proceedings of the ACM Multimedia′94 Conference Workshop on Multimedia Database Management Systems,San Francisco, California, October 1994
收稿日期:1999-01-22
