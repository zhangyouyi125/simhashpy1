计算机应用
Computer Applications
1999年 第19卷 第7期  Vol.19 No.7 1999



基于注释的视频索引*
郑　鹏　李订方　刘海青

　　摘　要　本文提出了表示视频数据库的数据模型，该模型通过视频注释来描述视频数据，并利用注释建立索引，以实现按内容访问视频数据库。
　　关键词　视频数据库，镜头，注释，索引
　　
ANNOTATION-BASED INDEX IN VIDEO DATABASE

Zheng Peng　Li Dingfang　Liu Haiqing
Department of Computer Science and Technology ,
Wuhan University of Hydraulic and Electrical Engineering, Hubei*Wuhan 430072

　　Abstract　In this paper, a kind of data model to represent video database and describe video data by annotation is presented, which builds up index by the annotations so that we can access video database based on content.
　　Keywords　Video database,Shot,Annotation,Index

　　在传统的关系型数据库管理系统中，呈现给用户的数据库是表示关系的二维表，利用关键字对数据进行索引。由于关键字不可能描述视频数据的时空关系，不能完全表示语义信息，并且不支持继承性、相似性，不能进行描述间的推理，因此选择关键字集合来索引视频数据不是一种好方法。
　　考虑到视频数据的特点，我们提出了基于特征的视频索引。对此人们开始引入进化算法,其主要思想是,在实时任务对资源需求呈较大幅度变化的条件下,根据实际需求的连续性,逐次递推出每一周期各个任务对资源需求的估计值,以此作为任务调度的依据,这方面的工作已经取得了一些有效的结果［11］。为此，我们提出了基于注释的视频索引。
1　数据模型与上下文
　　在视频流中有两个固有的抽象层次：整个视频流和单个帧。
　　(4) 把E3/L(C)作为匹配的相似度。在根据形状信息进行检索时,它们是用形状所具有的特征,如周长、面积、矩不变量等来描述形状,并由此建立索引,进行检索。镜头是摄像机在一次拍摄过程中所记录下的视频帧序列，加上特征和注释组成镜头库。有了镜头库后，我们就可根据应用的需要建立视频文档库，形成用户视图。视频文档可以是场景、序列、复合单元等。这些视频区间在不同的精细程度上反映了视频信息。我们把视频数据库系统看成是由存储的媒体段、镜头和视频文档三个层次组成。
　　负载均衡系数――设在第n帧中首先完成所有任务的PN执行时间为Qn,则我们定义

为第n帧内的负载均衡系数。
　　对镜头库而言，特征是指每个镜头所独有的，与其它镜头没有关系,我们称之为上下文无关；注释也是针对单个镜头进行的。对视频文档库而言，特征考虑到了视频区间之间的关系，离开了视频区间的环境，特征也就不复存在。对视频区间的注释依赖于上下文。而这一点正好反映了视频数据的时间维度。
　　正如前面数据模型中指出的那样，视频数据库中包含许多不同类型的信息。我们采用面向对象的方法，把每一类信息都定义成对象，相同类型的对象构成一个集合，几个集合的集合就构成视频数据库。为了便于浏览和查询，需要引入现实世界的关系实体对媒体流进行解释。视频文档可以包含结构信息，结构可用结构元素集来表示，每一个元素可识别一个视频流区间。在此我们设利用α-β-γ方法的估计误差上限为M,于是,

即为任务参量在第k帧中的估计上限值。
　　为了对基本段进行注释，引入几个语义实体：
　　人物： 包括姓名、年龄、国籍和职业等属性。
　　地点： 包括国名、省名和城市名等属性。
　　事件： 包括事件类型、事件发生的时间和对事件的描述等属性。
　　假设用户在平面上画出A,B,C,D这4个简单形状,如图4所示,图像库中的某个图像所包含的简单形状如图5所示,并且,通过简单形状相似性计算,已确定匹配关系：A1,B2,3,C4,6,D5,我们的问题是：在图5中是否存在形状子集｛a,b,c,d｝｛1,2,3,4,5,6｝,使得Aa,Bb,Cc,Dd,并且｛a,b,c,d｝与｛A,B,C,D｝有相同的相对空间关系。
　　由于视频数据还具有时间维度，所以在进行注释时，还应考虑视频段之间的关系，即视频段所处的上下文(context)［2］。因为对视频数据的注释与其上下文密切相关，对上下文的控制显得尤为重要。建立视频数据库的目的是有效地管理和利用视频，由于视频数据量的庞大，对视频段的共享和重用也是十分必要的。为此，我们把上下文分成三个层次：
　　基本上下文： 对存储的媒体段中的单个段进行的描述。
有关字段说明如下：我们把所有从图像库中提取的简单形状统一编号,给予每个简单形状给予一个唯一的形状号；为了加快检索速度,每个简单形状的特征量与其形状数据本身分开存放,形状数据可以是这个形状的BMP图形；所有图像也统一编号,给予每个图像一个唯一的图号；对每个简单形状,还要用一个图号标记它是从哪一个图像中提取出来的。因此,分布式实时系统中周期性任务的分配调度分为两个步骤：首先是确定每一帧内任务在各个PN上的分配策略,其次是确定各个PN对分配在其上的各个任务的调度策略。对视频文档的访问最后要映射到存储的媒体段上，物理存储与逻辑视图的分离有利于视频数据的共享和重用。
　　假设用户在平面上画出A,B,C,D这4个简单形状,如图4所示,图像库中的某个图像所包含的简单形状如图5所示,并且,通过简单形状相似性计算,已确定匹配关系：A1,B2,3,C4,6,D5,我们的问题是：在图5中是否存在形状子集｛a,b,c,d｝｛1,2,3,4,5,6｝,使得Aa,Bb,Cc,Dd,并且｛a,b,c,d｝与｛A,B,C,D｝有相同的相对空间关系。
　　次级上下文： 一个视频文档(D1)中的某些段被另一视频文档(D2)所共享，即出现在另一视频文档(D2)中，则在视频文档(D2)中对此共享段的描述称为视频文档(D1)的次级上下文。
　　提出三级上下文的原因是这样做可以更好地控制视频数据的共享和对视频数据的描述。在基本上下文中的注释，可被使用此存储媒体段的所有视频文档“看”到和共享，在某一视频文档的初级上下文中的注释不会与其它视频文档的初级上下文中的注释混淆，即使两者使用了某些相同的存储媒体段，在必要时，可使用次级上下文来搜索与当前上下文中的注释使用了相同存储媒体段的其它视频文档。
2　视频注释
　　我们可以利用这几个语义实体对基本段进行注释。注释就是与特定视频段相关的语义属性集。不同的视频段，其注释是不同的。
　　在存储的媒体流中，ms是存储的媒体段，(ms.SID)是其标识符，(ms.TS)是其绝对的起始时间，(ms.TE)是其绝对的终止时间，(ms.TimeUnitSize)是其时间坐标系统的时间单位。存储的媒体段的集合称为MS―Set。尽管这些方法首先是针对运动学或动力学问题而提出的,但其应用早已超出这两方面的范畴,这里提出的PAA算法即基于α-β-γ滤波方法,下面给出它的基本表达式：
　　状态方程

其中X(k)是所考虑参量在第k帧中的零阶、一阶及二阶导数构成的一维数组,w(k)为零均值的
高斯白噪声序列,

量测方程

其中y(k)为所考虑参量在第k帧的实际采样值,H(k)=［1 0 0］,v(k)是均值为0的高斯量测
噪声,其方差为σ。StreamInt定义如下：
　　StreamInt＝(oid,MS―ref,TS,TE) 其中
　　　TS≤TE∧存在ms∈MS―Set
　　　(MS―ref=ms∧ms.TS≤TS∧ms.TE≥TE)　　　(2)
　　MS―ref是ms的标识符，oid是视频流区间的标识符，TS、TE分别表示起始帧和终止帧。从(1)式可以看出视频流区间可以是相关视频存储段的一部分或全部。在此基础上定义视频注释如下：
　　Annot=(oid,a1,a2,...,am,SI―ref) 其中
　　SI―ref∈StreamInt―Set∧a1,a2,...,am
　　　　是具体的属性类型　　　　　　　(3)
　　在视频数据库中，除了语义注释可以帮助理解视频信息以外，视频结构也有助于理解视频信息。前面提出的层次模型支持对视频结构的解释。一般可把视频文档定义成镜头、场景、序列和复合单元。结构元素的一个重要方面就是能够表示不同精细程度的上下文，如表示镜头的上下文比表示序列的上下文要精细一些。
　　结构元素是结构元素集合(Struct―Set)的一个成员，定义如下：
　　StructComp=(oid,Type,a1,a2,...,am,SI―ref) 其中
　　　SI―ref∈StreamInt―Set
　　　∧эvs∈VS―Set(SI―ref.MS―ref=vs)
　　　∧Type∈{cu,seq,sence,shot}∧a1,a2,...,am是类型说明的属性　　　(4)
　　视频结构是与视频文档相关的，与存储的媒体段不相关，在我们的模型中指出了视频流有镜头、场景、序列、复合单元等。
　　图1说明了基于注释的索引。由于α-β-γ滤波器的主要特点是,在滤波增益确定以后,实时过程中不需要再考虑系统的运动及量测模型,因此各帧中的计算负担很小,这使得我们将其应用于存在大量独立任务的分布式系统成为可能。
　　注释a1-a6是在存储的媒体段上的基本上下文进行的，Rowe等［2］使用术语感觉索引(sensory indexes)表示这类信息，这类索引是独立于初级上下文的，反映了视频的语法信息。注释a7、a8是在视频文档的初级上下文中进行的，Rowe等使用术语主题索引来表示这类信息，这类索引依赖于用户对视频材料的使用方式和目的，反映了视频的语义信息。
3　结束语
　　随着多媒体、电视、通信技术的迅猛发展，视频数据日益增多。为了有效地管理和利用视频数据，人们自然想到建立视频数据库。由于视频数据的信息含量非常丰富，结构复杂多样，因此要想有效地检索视频数据，必须对视频数据建立索引。863-317-9604-05)资助。我们根据目前机器视觉的技术水平和视频数据的特点，提出了一种利用注释建立视频数据索引的方法。这一方法的优点是很好地反映了视频数据的语义特性，缺点是注释往往要手工进行，这就使得注释的成本较高并且与注释者有关，这一问题的解决依赖于人工智能的新进展。由于视频数据库是一个较新的领域，其索引方法有待进一步研究。
　　
　　郑　鹏　博士研究生。 研究方向：机器视觉与图像处理。
　　* 本文受国家电力公司计算机应用重点学科专项基金的资助。
　　作者单位：郑　鹏　李订方　刘海青（武汉水利电力大学计算机科学与技术系　湖北．武汉430072）
参考文献
［1］　Arun Hampapur. Design Video Data Management System. Ph.D thesis, 1995
［2］　L.A.Rowe, J.S.Boreczky，C.A.Eads. Indexes for User Access to Large Video Databases. In Proceedings of the IS&T/SPIE Symposium on Electronic Imaging Science and Technology, Conference on Storage and Retrieval for Image and Video DatabasesⅡ, San Jose,CA,February 1994
［3］　Rune Hjelsvold. Sharing and Reuse of Video Information. In Proceedings of the ACM Multimedia′94 Conference Workshop on Multimedia Database Management Systems,San Francisco, California, October 1994
收稿日期:1999-01-22
